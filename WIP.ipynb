{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import log_loss\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "from utils import _add_constant,_hat_diag,_sigmoid_pred,_sigmoid_pred, _information_matrix, _predict, _predict_proba\n",
    "#import R package brglm\n",
    "base = importr('base')\n",
    "d = {'package.dependencies': 'package_dot_dependencies',\n",
    "     'package_dependencies': 'package_uscore_dependencies'}\n",
    "brglm = importr('brglm',robject_translations=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "features = [i.replace(' ', '_') for i in load_breast_cancer().feature_names.tolist()]\n",
    "\n",
    "breast_cancer_df = pd.DataFrame(load_breast_cancer().data,columns=features)\n",
    "target_df = pd.DataFrame(load_breast_cancer().target, columns=['y'])\n",
    "X = breast_cancer_df.iloc[:,:5]\n",
    "y = target_df\n",
    "\n",
    "df = pd.concat([target_df,breast_cancer_df],axis=1).iloc[:,:6]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create small data set and rare event data set\n",
    "num_successes_for_rare = int(((((1-df.y.mean())*df.shape[0])/.95)-((1-df.y.mean())*df.shape[0]))//1)\n",
    "rare_inds = sorted(list(df[df.y==0].index) + random.sample(list(df[df.y==1].index),num_successes_for_rare))\n",
    "# small_inds = random.sample(sorted(list(df.index)),50)\n",
    "\n",
    "\n",
    "rare_df = df.iloc[rare_inds,:6]\n",
    "rare_X = rare_df.drop('y',axis=1)\n",
    "rare_y = rare_df['y']\n",
    "\n",
    "separation_df = pd.read_csv('separation_df.csv',index_col=0).iloc[:,:6]\n",
    "separation_X = separation_df.drop('y',axis=1)\n",
    "separation_y = separation_df['y']\n",
    "\n",
    "small_df = pd.read_csv('small_df.csv',index_col=0)\n",
    "small_X = small_df.drop('y',axis=1)\n",
    "small_y = small_df['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "def formula_from_df(df,y_var_name):\n",
    "    features = list((df.drop(y_var_name,axis=1).columns))\n",
    "    formula = y_var_name + '~' + ' + '.join(features)\n",
    "    return formula\n",
    "\n",
    "def Sigmoid_Pred(X, weights):\n",
    "    z = np.dot(X,weights)\n",
    "    sig =  1/(1 + np.exp(-1*z))\n",
    "    sig = np.clip(sig,.000001,.999999)\n",
    "    return sig\n",
    "\n",
    "def hat_diag(X,weights):\n",
    "    Xt = X.transpose()\n",
    "    \n",
    "    #Get diagonal of error\n",
    "    y_pred = Sigmoid_Pred(X,weights)\n",
    "    W = np.diag(y_pred*(1-y_pred))\n",
    "   \n",
    "    #Calculate Fisher Information Matrix\n",
    "    I = np.linalg.multi_dot([Xt,W,X]) \n",
    "\n",
    "    #Get Diagonal of Hat Matrix\n",
    "    hat = np.linalg.multi_dot([W**0.5,X,np.linalg.inv(I),Xt,W**0.5])\n",
    "    hat_diag = np.diag(hat)\n",
    "    return hat_diag\n",
    "\n",
    "def marginal_effects(X,weights):\n",
    "    #at means\n",
    "    column_means = X.mean()\n",
    "    p = Sigmoid_Pred(column_means,weights)\n",
    "    at_means = np.ones(6)\n",
    "    for i in range(weights.shape[0]):\n",
    "        weights_copy = c.copy()\n",
    "        weights_copy[i]+=1\n",
    "        new_p =Sigmoid_Pred(means,weights_copy)\n",
    "        at_means[i] = new_p-p\n",
    "    \n",
    "    #meaned\n",
    "    averaged_marg_effs = np.ones((X.shape[0],X.shape[1]))\n",
    "    for i in range(X.shape[0]):\n",
    "        row = X.iloc[i]\n",
    "        p = Sigmoid_Pred(row,c)\n",
    "        for j in range(weights.shape[0]):\n",
    "            weights_copy = weights.copy()\n",
    "            weights_copy[j]+=1\n",
    "            new_p = 1/(1+np.exp(-np.dot(row,weights_copy)))\n",
    "            eff = new_p-p\n",
    "            averaged_marg_effs[i,j] = eff\n",
    "        ame = pd.DataFrame(averaged_marg_effs.mean(axis=0),index=X.columns, columns=['mean'])\n",
    "        ame['at_means'] = at_means\n",
    "    return ame\n",
    "\n",
    "def information_matrix(X,weights):\n",
    "    Xt = X.transpose()\n",
    "\n",
    "    #Get diagonal of error\n",
    "    y_pred = Sigmoid_Pred(X,weights)\n",
    "    W = np.diag(y_pred*(1-y_pred))\n",
    "\n",
    "    #Calculate Fisher Information Matrix\n",
    "    I = np.linalg.multi_dot([Xt,W,X])\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#firth from scratch\n",
    "def firth_logit(X,y,num_iter=10000,alpha=0.01,add_int=True):\n",
    "    #add intercept if necessary\n",
    "    if add_int==True:\n",
    "        X = add_constant(X)\n",
    "    \n",
    "    #initialize weights\n",
    "    weights=np.ones(X.shape[1])\n",
    "    \n",
    "    #Perform gradient descent\n",
    "    for i in range(num_iter):\n",
    "        y_pred = Sigmoid_Pred(X,weights)\n",
    "        H = hat_diag(X,weights)\n",
    "        #Update weights\n",
    "        U = np.matmul((y -y_pred + H*(0.5 - y_pred)),X)\n",
    "        weights += np.matmul(np.linalg.inv(I),U)*alpha\n",
    "        if (i%1000==0):\n",
    "            print('log likelihood: ',(y*np.log(y_pred)+(1-y)*np.log(1-y_pred)).sum()+0.5*np.log(np.linalg.det(I)))\n",
    "    preds = Sigmoid_Pred(X,weights)\n",
    "    weights = pd.Series(weights,index=X.columns)\n",
    "    return preds, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firth_logit_r(df,y_var_name, formula, r_data=True, weights='none',all_coef_summary=False):\n",
    "    #convert data frame to R df\n",
    "    if r_data==False:\n",
    "        if type(weights) ==str:\n",
    "            with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "                df = ro.conversion.py2ri(df)\n",
    "        else:\n",
    "            with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "                df = ro.conversion.py2ri(df)\n",
    "                weights = ro.vectors.FloatVector(weights)\n",
    "    \n",
    "    #create firth logit model\n",
    "    if weights!='none':\n",
    "        model = brglm.brglm(formula, data = df, family='binomial',pl=True, weights=weights)\n",
    "    else:\n",
    "        model = brglm.brglm(formula, data = df, family='binomial',pl=True)\n",
    "    \n",
    "    #extract coefficients\n",
    "    summary = base.summary(model)\n",
    "    summary_dic = {}\n",
    "    for i in range(len(summary.names)):\n",
    "        try:\n",
    "            summary_dic[summary.names[i]]=pandas2ri.converter.ri2py(list(summary)[i])\n",
    "        except:\n",
    "            pass\n",
    "    columns = list(df.colnames)\n",
    "    columns[0]='Intercept'\n",
    "    if all_coef_summary==True:\n",
    "        coefs = pd.DataFrame(summary_dic['coefficients'],columns=(['Coef','SE','Z','P']),index=columns)\n",
    "    else:\n",
    "        coefs = pd.DataFrame(summary_dic['coefficients'],columns=(['Coef','SE','Z','P']),index=columns).Coef\n",
    "    \n",
    "    #get raw output and apply sigmoid\n",
    "    preds = ro.r.predict(model,df)\n",
    "    preds = 1/(1+np.exp(-np.array(preds)))       \n",
    "    return preds, coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#firth with hyperparameter\n",
    "def tuned_firth_logit(X,y,lmbda=0.5,num_iter=10000,alpha=0.01,add_int=True):\n",
    "    #add intercept if necessary\n",
    "    if add_int==True:\n",
    "        X = add_constant(X)\n",
    "    \n",
    "    #initialize weights\n",
    "    weights=np.ones(X.shape[1])\n",
    "    \n",
    "    #Perform gradient descent\n",
    "    for i in range(num_iter):\n",
    "        y_pred = Sigmoid_Pred(X,weights)\n",
    "        H = hat_diag(X,weights)\n",
    "        U = np.matmul((y -y_pred + lmbda*H*(1 - 2*y_pred)),X)\n",
    "        weights += np.matmul(np.linalg.inv(I),U)*alpha\n",
    "        if (i%1000==0):\n",
    "            print('log likelihood: ',(y*np.log(y_pred)+(1-y)*np.log(1-y_pred)).sum()+lmbda*np.log(np.linalg.det(I)))\n",
    "    return pd.Series(weights,index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLIC(X,y,num_iter=10000,lmbda=0.5):\n",
    "    #get firth logit coefs\n",
    "    coefs = tuned_firth_logit(X,y,lmbda=lmbda,num_iter=num_iter)\n",
    "    \n",
    "    #reestimate intercept\n",
    "    coefs.drop('const',inplace=True)\n",
    "    eta = np.dot(X,coefs)\n",
    "    target = y-eta\n",
    "    b0_model = sm.OLS(target,np.ones(y.shape[0])).fit()\n",
    "    b0 = b0_model.params[0]\n",
    "    coefs = pd.Series(b0,index=['Int']).append(coefs)\n",
    "    \n",
    "    #get predictions\n",
    "    X=add_constant(X)\n",
    "    preds = Sigmoid_Pred(X.values,coefs.values)\n",
    "    return preds,coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLIC_brglm(df, y_var_name):\n",
    "    formula = formula_from_df(df,y_var_name)\n",
    "    with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "        df_r = ro.conversion.py2ri(df)\n",
    "    model = brglm.brglm(formula, data = df_r, family='binomial',pl=True)\n",
    "    summary = base.summary(model)\n",
    "    summary_dic = {}\n",
    "    for i in range(len(summary.names)):\n",
    "        try:\n",
    "            summary_dic[summary.names[i]]=pandas2ri.converter.ri2py(list(summary)[i])\n",
    "        except:\n",
    "            pass\n",
    "    columns = list(firth_small_r.colnames)\n",
    "    coefs = pd.DataFrame(summary_dic['coefficients'],columns=(['Coef','SE','Z','P']),index=columns).Coef[1:]\n",
    "    y_var_name = formula.split('~')[0].strip()\n",
    "    y = df[y_var_name].values\n",
    "    X = df.drop(y_var_name,axis=1)\n",
    "    eta = np.dot(X,coefs)\n",
    "    target = y-eta\n",
    "    b0_model = sm.OLS(target,np.ones(y.shape[0])).fit()\n",
    "    b0 = pd.Series(b0_model.params[0],index=['Int'])\n",
    "    coefs = b0.append(coefs)\n",
    "    X=add_constant(X)\n",
    "    preds = Sigmoid_Pred(X.values,coefs.values)\n",
    "    return preds,coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLAC(X,y):\n",
    "    \n",
    "    init_rows = df.shape[0]\n",
    "    X = add_constant(X)\n",
    "    \n",
    "    \n",
    "    #Build Hat Matrix = (W**0.5)*X*((XtWX)^-1)*Xt*W**0.5\n",
    "    preds, weights = firth_logit_r(df=aug_df,\n",
    "                                 y_var_name=y_var_name,\n",
    "                                 formula=formula,\n",
    "                                 r_data=False,\n",
    "                                 weights=aug_sample_weights)\n",
    "    weights = model.params\n",
    "    H = hat_diag(X,weights)\n",
    "    \n",
    "    #Duplicate every row\n",
    "    double_df = df.append(df)\n",
    "    \n",
    "    #Create a new copy of the original data\n",
    "    pseudo_y_df = df\n",
    "    #Change y to 1-y\n",
    "    pseudo_y_df[y_var_name]=1-pseudo_y_df[y_var_name]\n",
    "    \n",
    "    #Append to doubled df\n",
    "    aug_df = double_df.append(pseudo_y_df)\n",
    "    \n",
    "    #Create dummy for real vs. duplicated/pseudo data\n",
    "    aug_df['real_data'] = 0\n",
    "    aug_df['real_data'][init_rows:]=1\n",
    "    \n",
    "    \n",
    "    #Create vector of weights = 1 for real data, hi/2 for augmentation data\n",
    "    aug_sample_weights = pd.Series(np.concatenate([np.ones(init_rows),H/2,H/2]))\n",
    "    \n",
    "    \n",
    "    #Get predictions and coefficients\n",
    "    logit = LogisticRegression(solver='newton-cg',penalty='none')\n",
    "    logit.fit(,y,sample_weights)\n",
    "    model = sm.Logit(y,).fit()\n",
    "    weights = model.params\n",
    "    \n",
    "    return preds, coefs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logF11(df,y_var_name,intercept=False):\n",
    "    '''Perform log-f(1,1) data augmentation\n",
    "       Returns augmented df and observation weights'''\n",
    "    \n",
    "    num_rows = 2*(df.shape[1]-1)\n",
    "    y_ind = df.columns.get_loc(y_var_name)\n",
    "    \n",
    "    aug = pd.DataFrame(0,columns=df.columns,index=(range(num_rows)))\n",
    "    \n",
    "    #augment y variable\n",
    "    aug.iloc[range(0,num_rows,2),y_ind]=1\n",
    "    y = aug[y_var_name]\n",
    "    \n",
    "    #augment X variables\n",
    "    X = aug.drop(y_var_name,axis=1)\n",
    "    for ind, rows in enumerate(range(0,X.shape[0],2)):\n",
    "         X.iloc[rows:rows+2,ind]=1\n",
    "    \n",
    "    #bring it all together\n",
    "    aug = pd.concat([y,X],axis=1)\n",
    "    f_df = df.append(aug)\n",
    "    \n",
    "    #add offset\n",
    "    f_df['real_data']=1\n",
    "    f_df['real_data'][-aug.shape[0]:]=0\n",
    "    \n",
    "    #reseparate\n",
    "    X = f_df.drop(y_var_name,axis=1)\n",
    "    y = f_df[y_var_name]\n",
    "    \n",
    "    #Calculate weights\n",
    "    weights = f_df['real_data'].apply(lambda x: 0.5 if x == 0 else 1)\n",
    "    model = sm.Logit(y,X).fit()\n",
    "    coefs = model.params\n",
    "    if intercept==True:\n",
    "        eta = np.dot(X,coefs)\n",
    "        target = y-eta\n",
    "        b0_model = sm.OLS(target,np.ones(y.shape[0])).fit()\n",
    "        b0 = pd.Series(b0_model.params[0],index=['Int'])\n",
    "        coefs = b0.append(coefs)\n",
    "        X=add_constant(X)\n",
    "\n",
    "    preds = Sigmoid_Pred(X.values,coefs)\n",
    "    return preds, coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intermediate versions that may be worth keeping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log-F(1,1) just augmentation\n",
    "def logF11_aug(df,y_var_name,R=False):\n",
    "    '''Perform log-f(1,1) data augmentation\n",
    "       Returns augmented df and observation weights'''\n",
    "    \n",
    "    num_rows = 2*(df.shape[1]-1)\n",
    "    y_ind = df.columns.get_loc(y_var_name)\n",
    "    \n",
    "    aug = pd.DataFrame(0,columns=df.columns,index=(range(num_rows)))\n",
    "    \n",
    "    #augment y variable\n",
    "    aug.iloc[range(0,num_rows,2),y_ind]=1\n",
    "    y = aug[y_var_name]\n",
    "    \n",
    "    #augment X variables\n",
    "    X = aug.drop(y_var_name,axis=1)\n",
    "    for ind, rows in enumerate(range(0,X.shape[0],2)):\n",
    "         X.iloc[rows:rows+2,ind]=1\n",
    "    \n",
    "    #bring it all together\n",
    "    aug = pd.concat([y,X],axis=1)\n",
    "    f_df = df.append(aug)\n",
    "    \n",
    "    #add offset\n",
    "    f_df['real_data']=1\n",
    "    f_df['real_data'][-aug.shape[0]:]=0\n",
    "    \n",
    "    #Calculate weights\n",
    "    weights = f_df['real_data'].apply(lambda x: 0.5 if x == 0 else 1)\n",
    "    if R==True:\n",
    "        with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    \n",
    "            f_df = ro.conversion.py2ri(f_df)\n",
    "            weights = ro.vectors.FloatVector(weights)\n",
    "    return f_df, weights      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FLAC just augmentation\n",
    "def FLAC_aug(df,y_var_name,R=False):\n",
    "    '''Perform FLAC data augmentation\n",
    "       Returns augmented df and observation weights'''\n",
    "    \n",
    "    init_rows = df.shape[0]\n",
    "    X = add_constant(df.drop(y_var_name,axis=1))\n",
    "    y = df[y_var_name]\n",
    "    glm = GLM(y,X,family=sm.families.Binomial()).fit()\n",
    "#     hat = glm.get_hat_matrix_diag()\n",
    "    weights = glm.params\n",
    "    y_pred = glm.predict(test_X)\n",
    "    W = np.diag(y_pred*(1-y_pred))\n",
    "    test_XtWtest_X = np.linalg.multi_dot([test_X.transpose(),W,test_X])\n",
    "    I = np.linalg.inv(test_XtWtest_X)\n",
    "    hat = np.diag(np.linalg.multi_dot([W**0.5,test_X,I,test_X.transpose(),W**0.5]))\n",
    "\n",
    "    aug_df = pd.concat([df,df,df])\n",
    "    aug_df[y_var_name][init_rows*2:]=1-aug_df[y_var_name][init_rows*2:]\n",
    "    aug_df['pseudo_data'] = 0\n",
    "    aug_df['pseudo_data'][init_rows:]=1\n",
    "\n",
    "    aug_sample_weights = pd.Series(np.concatenate([np.ones(init_rows),hat/2,hat/2]))\n",
    "    if R==True:\n",
    "        with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    \n",
    "            aug_df = ro.conversion.py2ri(aug_df)\n",
    "            aug_sample_weights = ro.vectors.FloatVector(aug_sample_weights)\n",
    "    return aug_df, aug_sample_weights\n",
    "    \n",
    "    #Now run this through brglm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ro.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3.])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ro.vectors.FloatVector(np.array([1,2,3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remycanario/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/remycanario/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2542: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "/Users/remycanario/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/remycanario/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/remycanario/anaconda3/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:890: RuntimeWarning: invalid value encountered in true_divide\n",
      "  n_endog_mu = self._clean((1. - endog) / (1. - mu))\n"
     ]
    }
   ],
   "source": [
    "#created augmented datasets\n",
    "\n",
    "#log-f(1,1)\n",
    "# all_f, all_weights_f = logf11_aug(all_df,'y')\n",
    "small_f, small_weights_f = logf11_aug(small_df,'y')\n",
    "rare_f, rare_weights_f = logf11_aug(rare_df,'y')\n",
    "separation_f, separation_weights_f = logf11_aug(separation_df,'y')\n",
    "\n",
    "#FLAC\n",
    "# all_FLAC, all_weights_FLAC = FLAC_aug(all_df,'y')\n",
    "small_FLAC, small_weights_FLAC = FLAC_aug(small_df,'y')\n",
    "rare_FLAC, rare_weights_FLAC = FLAC_aug(rare_df,'y')\n",
    "separation_FLAC, separation_weights_FLAC = FLAC_aug(separation_df,'y')\n",
    "\n",
    "#created R augmented datasets\n",
    "\n",
    "#log-f(1,1)\n",
    "# all_f, all_weights_f = logf11_aug(all_df,'y')\n",
    "small_f_r, small_weights_f_r = logf11_aug(small_df,'y')\n",
    "rare_f_r, rare_weights_f_r = logf11_aug(rare_df,'y')\n",
    "separation_f_r, separation_weights_f_r = logf11_aug(separation_df,'y')\n",
    "\n",
    "#FLAC\n",
    "# all_FLAC, all_weights_FLAC = FLAC_aug(all_df,'y')\n",
    "small_FLAC_r, small_weights_FLAC_r = FLAC_aug(small_df,'y')\n",
    "rare_FLAC_r, rare_weights_FLAC_r = FLAC_aug(rare_df,'y')\n",
    "separation_FLAC_r, separation_weights_FLAC_r = FLAC_aug(separation_df,'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boosted_firth(X,y,num_steps=500):\n",
    "    init_rows = X.shape[0]\n",
    "    aug_X = X.append(X)\n",
    "    aug_y = y.append(1-y)\n",
    "    eta0=np.full((1,,sm.Logit(aug_y,aug_X.const).fit().params[0])\n",
    "    weights = np.ones(aug_X.shape[1])\n",
    "    for i in range(num_steps):\n",
    "        hat_diag = hat(aug_X,weights)\n",
    "        y_pred = Sigmoid_Pred(aug_X,weights)\n",
    "        offset = (1+h/2)*(aug_y-y_pred*())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(df,y_var_name,X_train,y_train,X_test,y_test):\n",
    "    models = ['logit','l2','firth','FLIC','FLAC','log-f(1,1)','log-f(1,1)_with_int']\n",
    "\n",
    "    c_X_train = add_constant(X_train)\n",
    "    c_X_test = add_constant(X_test)\n",
    "    \n",
    "    base = sm.Logit(y_train,c_X_train).fit()\n",
    "    control_proba = base.predict(c_X_test)\n",
    "    control_preds = control_proba.round()\n",
    "    \n",
    "    l2 = LogisticRegression()\n",
    "    l2.fit(X_train,y_train)\n",
    "    l2_proba = l2.predict_proba(X_test)\n",
    "    l2_preds = l2.predict(X_test)\n",
    "    \n",
    "    firth_proba, firth_coefs = firth_logit(X_train,y_train)\n",
    "    firth_preds = firth_proba.round()\n",
    "    \n",
    "    FLIC_proba, FLIC_coefs = FLIC(X_train,y_train)\n",
    "    FLIC_preds = FLIC_proba.round()\n",
    "    \n",
    "    FLAC_proba, FLAC_coefs = FLAC_brglm(df,y_var_name)\n",
    "    FLAC_preds = FLAC_proba.round()\n",
    "    \n",
    "    logF11_proba, logF11_coefs = logF11(df,y_var_name)\n",
    "    logF11_preds = logF11_proba.round()\n",
    "    \n",
    "    logF11_int_proba, logF11_coefs = logF11(df,y_var_name,intercept=True)\n",
    "    logF11_int_preds = logF11_int_round()\n",
    "    \n",
    "    proba = [control_proba, l2_proba, firth_proba, FLIC_proba, FLAC_proba, logF11_proba, logF11_int_proba]\n",
    "    preds = [control_preds, l2_preds, firth_preds, FLIC_preds, FLAC_preds, logF11_preds, logF11_int_preds]\n",
    "    return proba, preds\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLAC(X,y):\n",
    "    \n",
    "    init_rows = df.shape[0]\n",
    "    X = add_constant(X)\n",
    "    \n",
    "    \n",
    "    #Build Hat Matrix = (W**0.5)*X*((XtWX)^-1)*Xt*W**0.5\n",
    "    preds, weights = firth_logit_r(df=aug_df,\n",
    "                                 y_var_name=y_var_name,\n",
    "                                 formula=formula,\n",
    "                                 r_data=False,\n",
    "                                 weights=aug_sample_weights)\n",
    "    weights = model.params\n",
    "    H = hat_diag(X,weights)\n",
    "    \n",
    "    #Duplicate every row\n",
    "    double_df = df.append(df)\n",
    "    \n",
    "    #Create a new copy of the original data\n",
    "    pseudo_y_df = df\n",
    "    #Change y to 1-y\n",
    "    pseudo_y_df[y_var_name]=1-pseudo_y_df[y_var_name]\n",
    "    \n",
    "    #Append to doubled df\n",
    "    aug_df = double_df.append(pseudo_y_df)\n",
    "    \n",
    "    #Create dummy for real vs. duplicated/pseudo data\n",
    "    aug_df['real_data'] = 0\n",
    "    aug_df['real_data'][init_rows:]=1\n",
    "    \n",
    "    \n",
    "    #Create vector of weights = 1 for real data, hi/2 for augmentation data\n",
    "    aug_sample_weights = pd.Series(np.concatenate([np.ones(init_rows),H/2,H/2]))\n",
    "    \n",
    "    \n",
    "    #Get predictions and coefficients\n",
    "    logit = LogisticRegression(solver='newton-cg',penalty='none')\n",
    "    logit.fit(,y,sample_weights)\n",
    "    model = sm.Logit(y,).fit()\n",
    "    weights = model.params\n",
    "    \n",
    "    return preds, coefs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remycanario/anaconda3/lib/python3.7/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=False,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='none',\n",
       "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklogit = LogisticRegression(solver='newton-cg',penalty='none',fit_intercept=False)\n",
    "sklogit.fit(small_X,small_y)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pd.Series(sklogit.coef_.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Firth Class\n",
    "#Things left to do: confidence intervals, Cauchy, generalize marginal effects\n",
    "class PMLE():\n",
    "    class Firth_Logit():\n",
    "        def __init__(self,num_iters=10000, alpha=0.01,add_int=True,lmbda=0.5,FLAC=False, FLIC=False):\n",
    "\n",
    "            self.alpha = alpha\n",
    "            self.num_iters = num_iters\n",
    "            self.add_int = add_int\n",
    "            self.lmbda=lmbda\n",
    "            self.FLAC = FLAC\n",
    "            self.FLIC=FLIC\n",
    "        \n",
    "        def firth_gd(self,X,y,weights):\n",
    "            y_pred = _sigmoid_pred(X=X,weights=weights)\n",
    "            H =_hat_diag(X,weights)\n",
    "            I = _information_matrix(X,weights)\n",
    "            U = np.matmul((y -y_pred + self.lmbda*H*(1 - 2*y_pred)),X)\n",
    "            weights += np.matmul(np.linalg.inv(I),U)*self.alpha\n",
    "            return weights\n",
    "        \n",
    "        def fit(self,X,y):\n",
    "            #add intercept if necessary\n",
    "            orig_X = X\n",
    "            if self.add_int==True:\n",
    "                X =_add_constant(X)\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "\n",
    "            #initialize weights\n",
    "            weights=np.ones(X.shape[1])\n",
    "            \n",
    "            \n",
    "            #Perform gradient descent\n",
    "            for i in range(self.num_iters):\n",
    "                weights = self.firth_gd(X,y,weights)\n",
    "            \n",
    "            if (self.FLAC==True)&(self.FLIC==True):\n",
    "                X,y,aug_sample_weights=_FLAC_aug(X,y,weights)\n",
    "                self.X = X\n",
    "                self.y = y\n",
    "                sklogit = LogisticRegression(solver='newton-cg',penalty='none',fit_intercept=False)\n",
    "                sklogit.fit(X,y,sample_weight=aug_sample_weights)\n",
    "                weights = sklogit.coef_[1:]\n",
    "                eta = np.dot(orig_X,weights)\n",
    "                target = y-eta\n",
    "                b0_model = sm.OLS(target,np.ones(y.shape[0])).fit()\n",
    "                b0 = b0_model.params[0]\n",
    "                weights = np.insert(weights,0,b0)\n",
    "            \n",
    "            elif self.FLAC==True:\n",
    "                X,y,aug_sample_weights=_FLAC_aug(X,y,weights)\n",
    "                self.X = X\n",
    "                self.y = y\n",
    "                sklogit = LogisticRegression(solver='newton-cg',penalty='none',fit_intercept=False)\n",
    "                sklogit.fit(X,y,sample_weight=aug_sample_weights)\n",
    "                weights = sklogit.coef_\n",
    "                \n",
    "            \n",
    "            elif self.FLIC==True:\n",
    "                weights = weights[1:]\n",
    "                eta = np.dot(orig_X,weights)\n",
    "                target = y-eta\n",
    "                b0_model = sm.OLS(target,np.ones(y.shape[0])).fit()\n",
    "                b0 = b0_model.params[0]\n",
    "                weights = np.insert(weights,0,b0)\n",
    "            \n",
    "            weights = pd.Series(weights.flatten(),index=self.X.columns)\n",
    "            self.weights = weights\n",
    "            \n",
    "            I = _information_matrix(X,weights)\n",
    "            hat_matrix_diag = _hat_diag(X,weights)\n",
    "            Hessian = -I\n",
    "            y_pred = _sigmoid_pred(X,weights)\n",
    "            \n",
    "            self.I = I\n",
    "            self.hat_matrix_diag = hat_matrix_diag\n",
    "            self.Hessian = Hessian\n",
    "            \n",
    "            \n",
    "            self.log_likelihood = (y*np.log(y_pred)+(1-y)*np.log(1-y_pred)).sum()+0.5*np.log(np.linalg.det(I))\n",
    "            \n",
    "        def predict(self,X):\n",
    "            if self.FLAC==True:\n",
    "                X = _FLAC_pred_aug(X)\n",
    "            if X.shape[1]==self.X.shape[1]-1:\n",
    "                X=_add_constant(X)\n",
    "            return _predict(X,self.weights)\n",
    "        \n",
    "        def predict_proba(self,X):\n",
    "            if self.FLAC==True:\n",
    "                X = _FLAC_pred_aug(X)\n",
    "            if X.shape[1]==self.X.shape[1]-1:\n",
    "                X=_add_constant(X)\n",
    "            return _predict_proba(X,self.weights)\n",
    "        \n",
    "        \n",
    "        def marginal_effects(self,values=None):\n",
    "                \n",
    "            def at_specific_values(self,values):\n",
    "                n_features = self.weights.shape[0]\n",
    "                if values.shape[0]==n_features-1:\n",
    "                    values = _add_constant(values)\n",
    "                \n",
    "                p = _sigmoid_pred(values,self.weights)\n",
    "                effs = np.ones(n_features)\n",
    "                for i in range(n_features):\n",
    "                    weights_copy = self.weights.copy()\n",
    "                    weights_copy[i]+=1\n",
    "                    new_p =_sigmoid_pred(values,weights_copy)\n",
    "                    effs[i] = new_p-p\n",
    "                return effs\n",
    "            \n",
    "            #at means\n",
    "            column_means = self.X.mean()\n",
    "            at_means = at_specific_values(weights=column_means)\n",
    "\n",
    "            #meaned\n",
    "            averaged_marg_effs = np.ones((self.X.shape[0],self.X.shape[1]))\n",
    "            for i in range(self.X.shape[0]):\n",
    "                row = self.X.iloc[i]\n",
    "                p = _sigmoid_pred(row,self.weights)\n",
    "                for j in range(self.weights.shape[0]):\n",
    "                    weights_copy = self.weights.copy()\n",
    "                    weights_copy[j]+=1\n",
    "                    new_p =_sigmoid_pred(row,weights_copy)\n",
    "                    eff = new_p-p\n",
    "                    averaged_marg_effs[i,j] = eff\n",
    "                ame = pd.DataFrame(averaged_marg_effs.mean(axis=0),index=self.X.columns, columns=['mean'])\n",
    "                ame['at_means'] = at_means\n",
    "            #user requested\n",
    "            if (type(values)==numpy.ndarray) | (type(values)==pandas.core.series.Series):\n",
    "                user_requested = at_specific_values(values)\n",
    "                ame['requested_values'] = user_requsted\n",
    "            return ame\n",
    "        \n",
    "        \n",
    "    \n",
    "    class logF11():\n",
    "        def __init__(self,intercept=False):\n",
    "            self.intercept=False\n",
    "        \n",
    "        def data_augementation(self,df,y_var_name):\n",
    "            num_rows = 2*(df.shape[1]-1)\n",
    "            y_ind = df.columns.get_loc(y_var_name)\n",
    "\n",
    "            aug = pd.DataFrame(0,columns=df.columns,index=(range(num_rows)))\n",
    "\n",
    "            #augment y variable\n",
    "            aug.iloc[range(0,num_rows,2),y_ind]=1\n",
    "            y = aug[y_var_name]\n",
    "\n",
    "            #augment X variables\n",
    "            X = aug.drop(y_var_name,axis=1)\n",
    "            for ind, rows in enumerate(range(0,X.shape[0],2)):\n",
    "                 X.iloc[rows:rows+2,ind]=1\n",
    "\n",
    "            #bring it all together\n",
    "            aug = pd.concat([y,X],axis=1)\n",
    "            f_df = df.append(aug)\n",
    "\n",
    "            #add offset\n",
    "            f_df['real_data']=1\n",
    "            f_df['real_data'][-aug.shape[0]:]=0\n",
    "            f_df['real_data'].apply(lambda x: 0.5 if x == 0 else 1)\n",
    "\n",
    "            #reseparate\n",
    "            X = f_df.drop(y_var_name,axis=1)\n",
    "            y = f_df[y_var_name]\n",
    "            \n",
    "            self.X = X\n",
    "            self.y = y\n",
    "    \n",
    "            return X, y\n",
    "        \n",
    "        def fit(self,df,y_var_name):\n",
    "            X, y = self.data_augementation(df,y_var_name)\n",
    "            model = sm.Logit(y,X).fit()\n",
    "            weights = model.params\n",
    "            if self.intercept==True:\n",
    "                eta = np.dot(X,weights)\n",
    "                target = y-eta\n",
    "                b0_model = sm.OLS(target,np.ones(y.shape[0])).fit()\n",
    "                b0 = b0_model.params[0]\n",
    "                weights = np.insert(weights,0,b0)\n",
    "                X = _add_constant(X)\n",
    "            self.X = X\n",
    "            weights = pd.Series(weights,index=X.columns)\n",
    "            self.weights = weights\n",
    "        \n",
    "        \n",
    "        \n",
    "        def predict(self,X):\n",
    "            return _predict(X,self.weights)\n",
    "        \n",
    "        def predict_proba(self,X):\n",
    "            return _predict_proba(X,self.weights)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = PMLE.Firth_Logit(num_iters=5000,FLAC=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remycanario/Documents/DataScience/wip-pmle/utils.py:18: RuntimeWarning: overflow encountered in exp\n",
      "  sig =  1/(1 + np.exp(-1*z))\n"
     ]
    }
   ],
   "source": [
    "f.fit(small_X,small_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted(X,y,weights,sample_weights):\n",
    "    one = sample_weights * (y*_sigmoid_pred(X,weights)-1) * y\n",
    "    two = np.dot(X.transpose(),one)\n",
    "    return two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = -np.sum(sample_weight * log_logistic(yz)) + .5 * alpha * np.dot(w, w)\n",
    "\n",
    "z = expit(yz)\n",
    "z0 = sample_weight * (z - 1) * y\n",
    "\n",
    "grad[:n_features] = safe_sparse_dot(X.T, z0) + alpha * w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z  = np.expit(y*np.dot(X,weights))\n",
    "z0 = sample_weights * (z-1) * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X,weights):\n",
    "    z = np.dot(X,weights)\n",
    "    hessian = ((X**2)*np.exp(z))/(1+np.exp(z))**2\n",
    "    return hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "1-dimensional array given. Array must be two-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-347-ad79cbd3b106>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFLIC_sigmoid_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmall_y\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mb0\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmulti_dot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mmulti_dot\u001b[0;34m(arrays)\u001b[0m\n\u001b[1;32m   2658\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2659\u001b[0m         \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2660\u001b[0;31m     \u001b[0m_assert_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2662\u001b[0m     \u001b[0;31m# _multi_dot_three is much faster than _multi_dot_matrix_chain_order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_assert_2d\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             raise LinAlgError('%d-dimensional array given. Array must be '\n\u001b[0;32m--> 201\u001b[0;31m                     'two-dimensional' % a.ndim)\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_assert_stacked_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: 1-dimensional array given. Array must be two-dimensional"
     ]
    }
   ],
   "source": [
    "num_iters = 5000\n",
    "eta = np.dot(small_X,f.weights[1:])\n",
    "b0 = 1\n",
    "X0 = np.ones((small_X.shape[0],1))\n",
    "for i in range(num_iters):\n",
    "    y_pred = FLIC_sigmoid_pred(X0,b0,eta)\n",
    "    W = np.diag(y_pred*(1-y_pred))\n",
    "    I = np.linalg.multi_dot([X0.transpose(),W,X0])\n",
    "    U = small_y-y_pred\n",
    "    b0 += (1/I)*U*0.01\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLIC_sigmoid_pred(X, weights,eta):\n",
    "    z = np.dot(X,weights)\n",
    "    sig =  1/(1 + np.exp(-z-eta))\n",
    "    sig = np.clip(sig,.000001,.999999)\n",
    "    return sig\n",
    "\n",
    "def _information_matrix(X,weights,eta):\n",
    "    Xt = X.transpose()\n",
    "\n",
    "    #Get diagonal of error\n",
    "    y_pred = FLIC_sigmoid_pred(X,weights,eta)\n",
    "    W = np.diag(y_pred*(1-y_pred))\n",
    "\n",
    "    #Calculate Fisher Information Matrix\n",
    "    I = np.linalg.multi_dot([Xt,W,X])\n",
    "    return I\n",
    "def U =\n",
    "\n",
    "def FLIC_two(X,y,weights):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.148958\n",
      "         Iterations 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remycanario/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2542: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "c_X_train = add_constant(X_train)\n",
    "c_X_test = add_constant(X_test)\n",
    "\n",
    "base = sm.Logit(y_train,c_X_train).fit()\n",
    "control_proba = base.predict(c_X_test)\n",
    "control_preds = control_proba.round()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = ['small','rare','separation']\n",
    "small_results = pd.DataFrame\n",
    "rare_results = pd.DataFrame\n",
    "separation_results = pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02826294061606858"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,small_control_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.])"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_l2_proba["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0])"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_l2_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08771929824561403"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,small_firth_proba.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rare_FLICFLAC_proba' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-459-7f42850e9724>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Logit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'L2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Firth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FLIC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FLAC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FLICFLAC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrare_control_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrare_l2_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrare_firth_proba\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrare_FLIC_proba\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrare_FLAC_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m114\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrare_FLICFLAC_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m114\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rare_FLICFLAC_proba' is not defined"
     ]
    }
   ],
   "source": [
    "labels = ['Logit', 'L2','Firth','FLIC','FLAC','FLICFLAC']\n",
    "results = [rare_control_proba, rare_l2_proba, rare_firth_proba,rare_FLIC_proba,rare_FLAC_proba[:114], rare_FLICFLAC_proba[:114]]\n",
    "\n",
    "metrics = []\n",
    "for result in results:\n",
    "    acc = accuracy_score(y_test,result.round())\n",
    "    bin_cross_entr = log_loss(y_test,result)\n",
    "    roc_auc = roc_auc_score(y_test,result)\n",
    "    metrics.append([acc,bin_cross_entr,roc_auc])\n",
    "\n",
    "rare_results = pd.DataFrame.from_dict(dict(zip(labels,metrics)))\n",
    "rare_results.index = ['Accuracy_Score','Binary_Cross_Entropy','ROC_AUC']\n",
    "rare_results = rare_results.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Logit', 'L2','Firth','FLIC','FLAC','FLICFLAC']\n",
    "results = [separation_control_proba, separation_l2_proba, \n",
    "           separation_firth_proba,separation_FLIC_proba,separation_FLAC_proba[:114],separation_FLICFLAC_proba[:114]]\n",
    "\n",
    "metrics = []\n",
    "for result in results:\n",
    "    acc = accuracy_score(y_test,result.round())\n",
    "    bin_cross_entr = log_loss(y_test,result)\n",
    "    roc_auc = roc_auc_score(y_test,result)\n",
    "    metrics.append([acc,bin_cross_entr,roc_auc])\n",
    "\n",
    "separation_results = pd.DataFrame.from_dict(dict(zip(labels,metrics)))\n",
    "separation_results.index = ['Accuracy_Score','Binary_Cross_Entropy','ROC_AUC']\n",
    "separation_results = separation_results.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy_Score</th>\n",
       "      <th>Binary_Cross_Entropy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logit</th>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.247381</td>\n",
       "      <td>0.988885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2</th>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.241874</td>\n",
       "      <td>0.962210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Firth</th>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.212465</td>\n",
       "      <td>0.973007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLIC</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.251296</td>\n",
       "      <td>0.973007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAC</th>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.211935</td>\n",
       "      <td>0.973007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy_Score  Binary_Cross_Entropy   ROC_AUC\n",
       "Logit        0.938596              0.247381  0.988885\n",
       "L2           0.912281              0.241874  0.962210\n",
       "Firth        0.921053              0.212465  0.973007\n",
       "FLIC         0.842105              0.251296  0.973007\n",
       "FLAC         0.921053              0.211935  0.973007"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "labels = ['Logit', 'L2','Firth','FLIC','FLAC','FLICFLAC']\n",
    "results = [small_control_proba, small_l2_proba, small_firth_proba,small_FLIC_proba,small_FLAC_proba[:114],small_FLICFLAC_proba[:114]]\n",
    "\n",
    "metrics = []\n",
    "for result in results:\n",
    "    acc = accuracy_score(y_test,result.round())\n",
    "    bin_cross_entr = log_loss(y_test,result)\n",
    "    roc_auc = roc_auc_score(y_test,result)\n",
    "    metrics.append([acc,bin_cross_entr,roc_auc])\n",
    "\n",
    "small_results = pd.DataFrame.from_dict(dict(zip(labels,metrics)))\n",
    "small_results.index = ['Accuracy_Score','Binary_Cross_Entropy','ROC_AUC']\n",
    "small_results = small_results.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy_Score</th>\n",
       "      <th>Binary_Cross_Entropy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logit</th>\n",
       "      <td>0.789474</td>\n",
       "      <td>1.156788</td>\n",
       "      <td>0.971737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2</th>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.877821</td>\n",
       "      <td>0.969197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Firth</th>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.787551</td>\n",
       "      <td>0.953636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLIC</th>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.497928</td>\n",
       "      <td>0.953636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAC</th>\n",
       "      <td>0.745614</td>\n",
       "      <td>0.818522</td>\n",
       "      <td>0.955224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy_Score  Binary_Cross_Entropy   ROC_AUC\n",
       "Logit        0.789474              1.156788  0.971737\n",
       "L2           0.614035              0.877821  0.969197\n",
       "Firth        0.771930              0.787551  0.953636\n",
       "FLIC         0.824561              0.497928  0.953636\n",
       "FLAC         0.745614              0.818522  0.955224"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy_Score</th>\n",
       "      <th>Binary_Cross_Entropy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logit</th>\n",
       "      <td>0.078947</td>\n",
       "      <td>6.210036</td>\n",
       "      <td>0.028263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2</th>\n",
       "      <td>0.105263</td>\n",
       "      <td>2.341475</td>\n",
       "      <td>0.031439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Firth</th>\n",
       "      <td>0.087719</td>\n",
       "      <td>3.814560</td>\n",
       "      <td>0.033026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLIC</th>\n",
       "      <td>0.149123</td>\n",
       "      <td>3.660701</td>\n",
       "      <td>0.033026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAC</th>\n",
       "      <td>0.087719</td>\n",
       "      <td>3.798521</td>\n",
       "      <td>0.033026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy_Score  Binary_Cross_Entropy   ROC_AUC\n",
       "Logit        0.078947              6.210036  0.028263\n",
       "L2           0.105263              2.341475  0.031439\n",
       "Firth        0.087719              3.814560  0.033026\n",
       "FLIC         0.149123              3.660701  0.033026\n",
       "FLAC         0.087719              3.798521  0.033026"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy_Score</th>\n",
       "      <th>Binary_Cross_Entropy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logit</th>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.247381</td>\n",
       "      <td>0.988885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2</th>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.241874</td>\n",
       "      <td>0.962210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Firth</th>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.212465</td>\n",
       "      <td>0.973007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLIC</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.251296</td>\n",
       "      <td>0.973007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAC</th>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.211935</td>\n",
       "      <td>0.973007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy_Score  Binary_Cross_Entropy   ROC_AUC\n",
       "Logit        0.938596              0.247381  0.988885\n",
       "L2           0.912281              0.241874  0.962210\n",
       "Firth        0.921053              0.212465  0.973007\n",
       "FLIC         0.842105              0.251296  0.973007\n",
       "FLAC         0.921053              0.211935  0.973007"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.199704\n",
      "         Iterations 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.027104\n",
      "         Iterations 15\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.104328\n",
      "         Iterations 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remycanario/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2542: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "/Users/remycanario/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/remycanario/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/remycanario/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#MLE\n",
    "base = sm.Logit(small_y,add_constant(small_X)).fit()\n",
    "small_control_proba = base.predict(add_constant(X_test))\n",
    "small_control_preds = control_proba.round()\n",
    "\n",
    "base = sm.Logit(rare_y,add_constant(rare_X)).fit()\n",
    "rare_control_proba = base.predict(add_constant(X_test))\n",
    "rare_control_preds = control_proba.round()\n",
    "\n",
    "try:\n",
    "    base = sm.Logit(separation_y,add_constant(separation_X)).fit()\n",
    "    separation_control_proba = base.predict(add_constant(X_test))\n",
    "    separation_control_preds = control_proba.round()\n",
    "except:\n",
    "    separation_control_proba = 'NA'\n",
    "    separation_control_preds = 'NA'\n",
    "\n",
    "#L2\n",
    "l2 = LogisticRegression()\n",
    "\n",
    "l2.fit(small_X,small_y)\n",
    "small_l2_proba = l2.predict_proba(X_test)[:,1]\n",
    "small_l2_preds = l2.predict(X_test)\n",
    "\n",
    "l2.fit(rare_X,rare_y)\n",
    "rare_l2_proba = l2.predict_proba(X_test)[:,1]\n",
    "rare_l2_preds = l2.predict(X_test)\n",
    "\n",
    "l2.fit(separation_X,separation_y)\n",
    "separation_l2_proba = l2.predict_proba(X_test)[:,1]\n",
    "separation_l2_preds = l2.predict(X_test)\n",
    "\n",
    "# #Firth\n",
    "# firth = PMLE.Firth_Logit(num_iters=5000)\n",
    "\n",
    "# firth.fit(small_X,small_y)\n",
    "# small_firth_proba = firth.predict_proba(X_test)\n",
    "# small_firth_preds = firth.predict(X_test)\n",
    "\n",
    "# firth.fit(rare_X,rare_y)\n",
    "# rare_firth_proba = firth.predict_proba(X_test)\n",
    "# rare_firth_preds = firth.predict(X_test)\n",
    "\n",
    "# firth.fit(separation_X,separation_y)\n",
    "# separation_firth_proba = firth.predict_proba(X_test)\n",
    "# separation_firth_preds = firth.predict(X_test)\n",
    "\n",
    "# #FLIC\n",
    "# FLIC = PMLE.Firth_Logit(num_iters=5000,FLIC=True)\n",
    "# FLIC.fit(small_X,small_y)\n",
    "# small_FLIC_proba = FLIC.predict_proba(X_test)\n",
    "# small_FLIC_preds = FLIC.predict(X_test)\n",
    "\n",
    "# FLIC.fit(rare_X,rare_y)\n",
    "# rare_FLIC_proba = FLIC.predict_proba(X_test)\n",
    "# rare_FLIC_preds = FLIC.predict(X_test)\n",
    "\n",
    "# FLIC.fit(separation_X,separation_y)\n",
    "# separation_FLIC_proba = FLIC.predict_proba(X_test)\n",
    "# separation_FLIC_preds = FLIC.predict(X_test)\n",
    "\n",
    "# #FLAC\n",
    "# FLAC = PMLE.Firth_Logit(num_iters=5000,FLAC=True)\n",
    "# FLAC.fit(small_X,small_y)\n",
    "# small_FLAC_proba = FLAC.predict_proba(X_test)\n",
    "# small_FLAC_preds = FLAC.predict(X_test)\n",
    "\n",
    "# FLAC.fit(rare_X,rare_y)\n",
    "# rare_FLAC_proba = FLAC.predict_proba(X_test)\n",
    "# rare_FLAC_preds = FLAC.predict(X_test)\n",
    "\n",
    "# FLAC.fit(separation_X,separation_y)\n",
    "# separation_FLAC_proba = FLAC.predict_proba(X_test)\n",
    "# separation_FLAC_preds = FLAC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remycanario/Documents/DataScience/wip-pmle/utils.py:18: RuntimeWarning: overflow encountered in exp\n",
      "  sig =  1/(1 + np.exp(-1*z))\n",
      "/Users/remycanario/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/remycanario/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "FLAC = PMLE.Firth_Logit(num_iters=5000,FLAC=True)\n",
    "FLAC.fit(small_X,small_y)\n",
    "small_FLAC_proba = FLAC.predict_proba(X_test)\n",
    "small_FLAC_preds = FLAC.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remycanario/Documents/DataScience/wip-pmle/utils.py:18: RuntimeWarning: overflow encountered in exp\n",
      "  sig =  1/(1 + np.exp(-1*z))\n",
      "/Users/remycanario/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/remycanario/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Firth_Logit' object has no attribute 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-458-fb299d4e4757>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mFLICFLAC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPMLE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFirth_Logit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFLAC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFLIC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mFLAC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmall_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msmall_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msmall_FLICFLAC_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFLICFLAC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msmall_FLICFLAC_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFLICFLAC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mFLICFLAC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPMLE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFirth_Logit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFLAC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFLIC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-384-d2a7cb24e284>\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAC\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FLAC_pred_aug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_add_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Firth_Logit' object has no attribute 'X'"
     ]
    }
   ],
   "source": [
    "FLICFLAC = PMLE.Firth_Logit(num_iters=5000,FLAC=True,FLIC=True)\n",
    "FLAC.fit(small_X,small_y)\n",
    "small_FLICFLAC_proba = FLICFLAC.predict_proba(X_test)\n",
    "small_FLICFLAC_preds = FLICFLAC.predict(X_test)\n",
    "FLICFLAC = PMLE.Firth_Logit(num_iters=5000,FLAC=True,FLIC=True)\n",
    "FLAC.fit(rare_X,rare_y)\n",
    "rare_FLICFLAC_proba = FLICFLAC.predict_proba(X_test)\n",
    "rare_FLICFLAC_preds = FLICFLAC.predict(X_test)\n",
    "FLICFLAC = PMLE.Firth_Logit(num_iters=5000,FLAC=True,FLIC=True)\n",
    "FLAC.fit(separation_X,separation_y)\n",
    "separation_FLICFLAC_proba = FLICFLAC.predict_proba(X_test)\n",
    "separation_FLICFLAC_preds = FLICFLAC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(342,)"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLICFLAC = PMLE.Firth_Logit(num_iters=5000,FLAC=True,FLIC=True)\n",
    "FLAC.fit(separation_X,separation_y)\n",
    "separation_FLICFLAC_proba = FLICFLAC.predict_proba(X_test)\n",
    "separation_FLICFLAC_preds = FLICFLAC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLAC_aug(X,y,weights):\n",
    "    init_rows = X.shape[0]\n",
    "    hat_diag = _hat_diag(X,weights)\n",
    "    aug_sample_weights = pd.Series(np.concatenate([np.ones(init_rows),hat_diag/2,hat_diag/2]))\n",
    "\n",
    "    X = X.append(X).append(X)\n",
    "    X['pseudo_data']=0\n",
    "    X['pseudo_data'][init_rows:]=1\n",
    "    y = y.append(y).append(1-y)\n",
    "    return X, y, aug_sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLAC_aug(X,weights,y=None):\n",
    "    init_rows = X.shape[0]\n",
    "    hat_diag = _hat_diag(X,weights)\n",
    "    aug_sample_weights = pd.Series(np.concatenate([np.ones(init_rows),hat_diag/2,hat_diag/2]))\n",
    "\n",
    "    X = X.append(X).append(X)\n",
    "    X['pseudo_data']=0\n",
    "    X['pseudo_data'][init_rows:]=1\n",
    "    if isinstance(y, np.ndarray) | isinstance(y, pd.DataFrame):\n",
    "       \n",
    "        y = y.append(y).append(1-y)\n",
    "    return X, y, aug_sample_weights\n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklogit = LogisticRegression(solver='newton-cg',penalty='none',fit_intercept=False)\n",
    "    sklogit.fit(X,y,sample_weight=aug_sample_weights)\n",
    "    weights = sklogit.coef_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
